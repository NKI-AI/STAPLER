# https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.callbacks.ModelCheckpoint.html

# Save the model periodically by monitoring a quantity.
# Look at the above link for more detailed information.
model_checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: ${oc.env:CHECKPOINT_PATH}train/folds/ # directory to save the model file
  filename: "train_checkpoint_epoch-{epoch:02d}-loss-{loss:.3f}-val-ap{val_cls_ap:.3f}" # checkpoint filename
  monitor: "val_cls_ap" # name of the logged metric which determines when model is improving
  verbose: False # verbosity mode
  save_last: False # additionally always save an exact copy of the last checkpoint to a file last.ckpt
  save_top_k: 1 # save k best models (determined by above metric)
  mode: "max" # "max" means higher metric value is better, can be also "min"
  auto_insert_metric_name: False # when True, the checkpoints filenames will contain the metric name
  save_weights_only: True # if True, then only the modelâ€™s weights will be saved
  every_n_train_steps: null # number of training steps between checkpoints
  train_time_interval: null # checkpoints are monitored at the specified time interval
  every_n_epochs: 1 # number of epochs between checkpoints
  save_on_train_epoch_end: True # whether to run checkpointing at the end of the training epoch or the end of validation